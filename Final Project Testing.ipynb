{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gega/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lr\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "import noisereduce as nr\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "SR = 16000\n",
    "n_mfcc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 16000\n",
    "EXTRA_LENGTH = 5000\n",
    "def significant_part(data):\n",
    "    curr_data = data.copy()\n",
    "    \n",
    "    curr_data = np.concatenate((np.zeros((EXTRA_LENGTH,), dtype=float), curr_data), axis=None)\n",
    "    curr_data = np.concatenate((curr_data, np.zeros((EXTRA_LENGTH,), dtype=float)), axis=None)\n",
    "    if len(curr_data) <= LENGTH + 2 * EXTRA_LENGTH:\n",
    "        zeros = LENGTH - len(curr_data) + 3 + 2 * EXTRA_LENGTH\n",
    "        curr_data = np.concatenate((curr_data, np.zeros((zeros,), dtype=float)), axis=None)\n",
    "    \n",
    "    max_sum = 0\n",
    "    result = curr_data[0:LENGTH + 2 * EXTRA_LENGTH]\n",
    "    for i in range(EXTRA_LENGTH, LENGTH + EXTRA_LENGTH):\n",
    "        max_sum += abs(curr_data[i])\n",
    "        \n",
    "    curr_sum = max_sum\n",
    "    for i in range(LENGTH + EXTRA_LENGTH, len(curr_data) - EXTRA_LENGTH):\n",
    "        curr_sum += abs(curr_data[i])\n",
    "        curr_sum -= abs(curr_data[i - LENGTH])\n",
    "        \n",
    "        if curr_sum > max_sum:\n",
    "            max_sum = curr_sum\n",
    "            result = curr_data[i - LENGTH - EXTRA_LENGTH:i + EXTRA_LENGTH]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    voices, files = [], []\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "    \n",
    "        for filename in filenames:\n",
    "            audio, sr = lr.load(os.path.join(dirpath, filename), mono=True, sr=SR)\n",
    "            audio = significant_part(audio)\n",
    "            voices += [audio]\n",
    "            files += [filename]\n",
    "            \n",
    "    return voices, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfccs(voices):\n",
    "    return [librosa.feature.mfcc(voice, sr=SR, n_mfcc=n_mfcc) for voice in voices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('result_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"result_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_voices, test_filenames = load_test_data(\"./Tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mfccs = get_mfccs(test_voices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mfcc_length = test_mfccs[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(test_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], n_mfcc, max_mfcc_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normilize(prediction):\n",
    "    normilized_prediction = []\n",
    "    prediction_sum = sum(prediction)\n",
    "    \n",
    "    for prob in prediction:\n",
    "        normilized_prediction.append(float(prob) / prediction_sum)\n",
    "    \n",
    "    return normilized_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normilized_predictions = []\n",
    "for index in range(0, len(predictions)):\n",
    "    curr_predict = normilize(predictions[index])\n",
    "    normilized_predictions.append(curr_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [x[:-4] for x in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "df_sub[0] = pd.DataFrame(test_filenames)[0]\n",
    "df_sub[1] = pd.DataFrame(normilized_predictions)[0]\n",
    "df_sub[2] = pd.DataFrame(normilized_predictions)[1]\n",
    "df_sub[3] = pd.DataFrame(normilized_predictions)[2]\n",
    "df_sub[4] = pd.DataFrame(normilized_predictions)[3]\n",
    "df_sub[5] = pd.DataFrame(normilized_predictions)[4]\n",
    "df_sub.to_csv(\"10.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
